{
 "metadata": {
  "name": "",
  "signature": "sha256:9026666f15d708431f1701336d4e84c2b4c3ee79f97fa1ba9f9a27f8f4386396"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from __future__ import division\n",
      "import nltk\n",
      "import json\n",
      "import requests\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from sklearn import naive_bayes, cross_validation, linear_model\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 5 - Fresh Predictions\n",
      "*Author - Theo Love*\n",
      "*Date - 3/9/2015*\n",
      "\n",
      "This is an extension of the work done on the Rotten Tomatoes database of critic reveiws to predict the \"freshness\" of a movie.\n",
      "\n",
      "**Contents**\n",
      "1. Helper Functions\n",
      "2. Data Import\n",
      "3. Exploration of N-Grams\n",
      "4. Stopwords\n",
      "5. Sentiment Scores\n",
      "6. Conclusions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1. Helper Functions\n",
      "\n",
      "These functions are based on work done in class and will be used in the code below. In order to keep everything in one workbook, they have **not** been migrated to a separate module, but may be at some point in the future."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_measure(classifier, x, y, tsize=0.25, rstate=1234, print_details=False):\n",
      "    \"\"\"\n",
      "    Function accepts a classifer from sklearn and computes the accuracy measure for a random train and test split\n",
      "    and returns a tuple of (train accuracy, test accuracy)\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=tsize, random_state=rstate)\n",
      "    clf = classifier.fit(xtrain, ytrain)\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = clf.score(xtrain, ytrain)\n",
      "    test_accuracy = clf.score(xtest, ytest)\n",
      "    if print_details:\n",
      "        print classifier\n",
      "        print \"Accuracy on training data: %0.4f\" % (training_accuracy)\n",
      "        print \"Accuracy on test data:     %0.4f\" % (test_accuracy)\n",
      "    \n",
      "    return (training_accuracy, test_accuracy)\n",
      "\n",
      "def test_alphas_NB(x, y, tsize=0.25, rstate=1234, alphas=[1], multi=True):\n",
      "    \"\"\"\n",
      "    Return a dataframe of train/test scores for naive-bayes models at each alpha in a list.\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    alphas    : the list of alphas to test (optional, default is 1)\n",
      "    multi     : true for a Multinomial Naive-Bayes, false for Bernoulli (optional, default is True)\n",
      "    \"\"\"\n",
      "    trains = []\n",
      "    tests = []\n",
      "    for a in alphas:\n",
      "        if multi:\n",
      "            clf = naive_bayes.MultinomialNB(alpha=a)\n",
      "        else:\n",
      "            clf = naive_bayes.BernoulliNB(alpha=a)\n",
      "        r = train_and_measure(clf, x, y, tsize, rstate, print_details=False)\n",
      "        trains.append(r[0])\n",
      "        tests.append(r[1])\n",
      "\n",
      "    return pd.DataFrame({'alpha': alphas,\n",
      "                         'train_score': trains,\n",
      "                         'test_score': tests})\n",
      "\n",
      "def k_cross(classifier, x, y, nfolds=2, rstate=1234):\n",
      "    \"\"\"\n",
      "    Function that takes a classifier from sklearn and returns a tuple of the (mean, std dev) for a k-fold train/test\n",
      "    split on a dependent y vector and independent matrix x.\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of independent variables\n",
      "    y         : a vector for the dependent variable\n",
      "    nfolds    : the number of folds in the k-fold test (optional, default is 2)\n",
      "    rstate    : the seed for the random number generator in the k-fold shuffler (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    kfold = cross_validation.KFold(n=x.shape[0], n_folds=nfolds, shuffle=True, random_state=rstate)\n",
      "    train_acc = []\n",
      "    test_acc = []\n",
      "    \n",
      "    for train_index, test_index in kfold:\n",
      "        clf = classifier.fit(x[train_index], y[train_index])\n",
      "        train_acc.append(clf.score(x[train_index], y[train_index]))\n",
      "        test_acc.append(clf.score(x[test_index], y[test_index]))\n",
      "\n",
      "    return (np.array(test_acc).mean(), np.array(test_acc).std())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2. Data Import"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in the data and get the length of the quotes\n",
      "critics = pd.read_csv('../DAT18NYC/data/rt_critics.csv')\n",
      "critics['quote_len'] = critics.quote.apply(lambda x: len(x))\n",
      "\n",
      "# print some pertinent data\n",
      "print \"Unique movies: %i\" % len(critics.title.unique())\n",
      "print \"Unique critics: %i\" % len(critics.critic.unique())\n",
      "print \"Fresh\\\\Rotten: %i\\\\%i\" % (len(critics[critics.fresh == 'fresh']), len(critics[critics.fresh == 'rotten']))\n",
      "print\n",
      "print \"Description of quote lengths\"\n",
      "print \"============================\"\n",
      "print critics.quote_len.describe()\n",
      "print \n",
      "print \"Columns\"\n",
      "print \"=======\"\n",
      "print critics.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique movies: 1736\n",
        "Unique critics: 622\n",
        "Fresh\\Rotten: 8613\\5436\n",
        "\n",
        "Description of quote lengths\n",
        "============================\n",
        "count    14072.000000\n",
        "mean       118.204946\n",
        "std         57.757129\n",
        "min          4.000000\n",
        "25%         73.000000\n",
        "50%        115.000000\n",
        "75%        160.000000\n",
        "max        256.000000\n",
        "dtype: float64\n",
        "\n",
        "Columns\n",
        "=======\n",
        "Index([u'critic', u'fresh', u'imdb', u'publication', u'quote', u'review_date', u'rtid', u'title', u'quote_len'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also interesting to see that a little less than 40% of the reviews are rotten, meaning that there is a bias towards \"fresh\" in the reviews.\n",
      "\n",
      "The summary of the data shows that the length of each quote is a maximum of 256 characters, which is rather small, and further suggests the usage of the Bernoulli implrementation of the Naive Bayes model. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3. Exploration of N-Grams\n",
      "\n",
      "The first new analysis to be done is to see if including additional number word groupings has any effect. Since the quotes are all rather short, the largest n-gram to be analyzed will be 5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the y as the fresh column with a 1 or 0\n",
      "y = (critics.fresh == 'fresh').values.astype(int)\n",
      "\n",
      "# make a sparse matrix for a number of ngrams\n",
      "x1 = CountVectorizer(ngram_range=(1,1)).fit_transform(critics.quote)\n",
      "x2 = CountVectorizer(ngram_range=(2,2)).fit_transform(critics.quote)\n",
      "x3 = CountVectorizer(ngram_range=(3,3)).fit_transform(critics.quote)\n",
      "x4 = CountVectorizer(ngram_range=(4,4)).fit_transform(critics.quote)\n",
      "x5 = CountVectorizer(ngram_range=(5,5)).fit_transform(critics.quote)\n",
      "x1to2 = CountVectorizer(ngram_range=(1,2)).fit_transform(critics.quote)\n",
      "x1to3 = CountVectorizer(ngram_range=(1,3)).fit_transform(critics.quote)\n",
      "x1to4 = CountVectorizer(ngram_range=(1,4)).fit_transform(critics.quote)\n",
      "x1to5 = CountVectorizer(ngram_range=(1,5)).fit_transform(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show train/test scores for the BernoulliNB classifiers with varying alpha\n",
      "print \"N-grams = 1\"\n",
      "print test_alphas_NB((x1 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 2\"\n",
      "print test_alphas_NB((x2 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 3\"\n",
      "print test_alphas_NB((x3 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 4\"\n",
      "print test_alphas_NB((x4 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 5\"\n",
      "print test_alphas_NB((x5 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 2\"\n",
      "print test_alphas_NB((x1to2 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 3\"\n",
      "print test_alphas_NB((x1to3 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 4\"\n",
      "print test_alphas_NB((x1to4 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 5\"\n",
      "print test_alphas_NB((x1to5 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "N-grams = 1\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612897     0.629516\n",
        "1  0.1000    0.610766     0.646690\n",
        "2  0.0100    0.610943     0.648466\n",
        "3  0.0010    0.610410     0.648111\n",
        "4  0.0001    0.609877     0.648229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 2\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.607746     0.626555\n",
        "1  0.1000    0.607390     0.627384\n",
        "2  0.0100    0.608101     0.627739\n",
        "3  0.0010    0.607568     0.627739\n",
        "4  0.0001    0.607213     0.627857"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 3\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610410     0.617198\n",
        "1  0.1000    0.610410     0.617198\n",
        "2  0.0100    0.610410     0.617198\n",
        "3  0.0010    0.610766     0.617198\n",
        "4  0.0001    0.611476     0.617198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 4\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.614592\n",
        "1  0.1000    0.610055     0.614592\n",
        "2  0.0100    0.610055     0.614592\n",
        "3  0.0010    0.610055     0.614592\n",
        "4  0.0001    0.610233     0.614592"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 5\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.613763\n",
        "1  0.1000    0.610055     0.613763\n",
        "2  0.0100    0.610055     0.613763\n",
        "3  0.0010    0.610055     0.613763\n",
        "4  0.0001    0.610055     0.613763"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 2\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612187     0.631529\n",
        "1  0.1000    0.609167     0.648822\n",
        "2  0.0100    0.610233     0.653914\n",
        "3  0.0010    0.609877     0.653796\n",
        "4  0.0001    0.608812     0.653441"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 3\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.611654     0.631292\n",
        "1  0.1000    0.608989     0.647400\n",
        "2  0.0100    0.610055     0.651783\n",
        "3  0.0010    0.609167     0.654151\n",
        "4  0.0001    0.609167     0.653441"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 4\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.611832     0.631292\n",
        "1  0.1000    0.609344     0.647045\n",
        "2  0.0100    0.610055     0.650953\n",
        "3  0.0010    0.610233     0.653559\n",
        "4  0.0001    0.609344     0.653559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 5\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612009     0.631292\n",
        "1  0.1000    0.609700     0.646690\n",
        "2  0.0100    0.610233     0.650717\n",
        "3  0.0010    0.610943     0.653678\n",
        "4  0.0001    0.610055     0.653559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These results show a few interesting things:\n",
      "\n",
      "1. Improvements in accuracy as alpha is decreased level out at around alpha = 0.01 (which will be used going forward)\n",
      "2. There is a slight decrease in the training score for single level n-grams, but not much of an affect on the test score. In general the testing score stays at 61%, and the range between the two gets tighter.\n",
      "3. There is not much improvement in accuracy for including higher ngrams, and in general the accuracy levels out at about 65% train / 61% test, which is still a nice tight range.\n",
      "\n",
      "Next we will examine confusion matrices"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show confusion matrix for each of the ngram x sets\n",
      "print \"Bernoulli Confusion Matrix\"\n",
      "print \"[[False, FalsePos]\"\n",
      "print \" [FalseNeg, True]]\"\n",
      "print\n",
      "clf = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "\n",
      "print \"Constant Size NGrams\"\n",
      "print \"====================\"\n",
      "print \"NGrams = 1\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1))\n",
      "print \"NGrams = 2\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x2))\n",
      "print \"NGrams = 3\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x3, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x3))\n",
      "print \"NGrams = 4\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x4, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x4))\n",
      "print \"NGrams = 5\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x5, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x5))\n",
      "print\n",
      "\n",
      "print \"Increasing Size NGrams\"\n",
      "print \"======================\"\n",
      "print \"NGrams = 1 to 2\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to2))\n",
      "print \"NGrams = 1 to 3\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to3, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to3))\n",
      "print \"NGrams = 1 to 4\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to4, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to4))\n",
      "print \"NGrams = 1 to 5\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to5, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bernoulli Confusion Matrix\n",
        "[[False, FalsePos]\n",
        " [FalseNeg, True]]\n",
        "\n",
        "Constant Size NGrams\n",
        "====================\n",
        "NGrams = 1\n",
        "[[3507 1952]\n",
        " [4458 4155]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 2\n",
        "[[4773  686]\n",
        " [7159 1454]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 3\n",
        "[[5250  209]\n",
        " [8220  393]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 4\n",
        "[[5150  309]\n",
        " [8134  479]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 5\n",
        "[[5012  447]\n",
        " [7932  681]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Increasing Size NGrams\n",
        "======================\n",
        "NGrams = 1 to 2\n",
        "[[4503  956]\n",
        " [6284 2329]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 3\n",
        "[[5082  377]\n",
        " [7518 1095]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 4\n",
        "[[5252  207]\n",
        " [8019  594]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 5\n",
        "[[5319  140]\n",
        " [8203  410]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While the accuracy of the training went up slightly with more ngrams, the test accuracy remained similar. Drilling down with a confusion matrix we see a much clearer trend of a major issue with false negatives, and a drastic cut in the number of true guesses.\n",
      "\n",
      "Essentially, the main difference between the models is that they are all aorund 61% accurate, but including additional n-grams tilts results drastically negative and makes the number of false negatives through the roof.\n",
      "\n",
      "It is also worth pointing out that all these regressions are actually providing results on test data that are essentially the same as always choosing \"fresh\" (which yields a 61.2% accuracy in the full data set).\n",
      "\n",
      "Let's see if we can do some additional wrangling to help with our false-negative problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Stop Words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test to see if the stops words matter\n",
      "clf = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "x_new = CountVectorizer(ngram_range=(1,2), stop_words='english').fit_transform(critics.quote)\n",
      "\n",
      "print \"Base 1 to 2 NGrams\"\n",
      "print \"==================\"\n",
      "train_and_measure(clf, (x1to2 > 1), y, tsize=0.4, print_details=True)\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to2))\n",
      "print\n",
      "print \"W/o Stop Words\"\n",
      "print \"==================\"\n",
      "train_and_measure(clf, (x_new > 1), y, tsize=0.4, print_details=True)\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x_new, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x_new))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Base 1 to 2 NGrams\n",
        "==================\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6525\n",
        "Accuracy on test data:     0.6090\n",
        "[[4503  956]\n",
        " [6284 2329]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "W/o Stop Words\n",
        "==================\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6405\n",
        "Accuracy on test data:     0.6060\n",
        "[[4694  765]\n",
        " [6801 1812]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Removing stop words, at least those in the sklearn package, actually make the accuracy worse, so it doesn't help us much with a Bernoulli Naive Bayes model."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##5. Sentiment Scores\n",
      "\n",
      "The next section gets the sentiment score for each quote, but since it takes a long time to run, I recommend using the next code chunk to just import the finished data.\n",
      "\n",
      "**Warning: the next code section took 20 minutes to run, so skip it, and go to the next section to import just the finished dataset**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let us use the text2sentiment tool to get a sentiment score for each quote\n",
      "def sentiment_score(sentence):\n",
      "    url = 'http://www.datasciencetoolkit.org/text2sentiment/'\n",
      "    payload = {'text': sentence} # The sentence we want the sentiment of \n",
      "    headers = {'content-type': 'application/json'} # The type of data you are sending\n",
      "    r = requests.post(url, data=json.dumps(payload), headers=headers) # Send the data\n",
      "    return json.loads(r.text)['score'] # return the tuple\n",
      "\n",
      "critics['quote_score'] = critics.quote.apply(lambda x: sentiment_score(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "######\n",
      "# IMPORT COMPLETED DATA\n",
      "######\n",
      "c = pd.read_csv('critics2.csv')\n",
      "c.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>quote_len</th>\n",
        "      <th>quote_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 137</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  33</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  79</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 107</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 110</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 40,
       "text": [
        "   Unnamed: 0              critic  fresh    imdb     publication  \\\n",
        "0           0         Derek Adams  fresh  114709        Time Out   \n",
        "1           1     Richard Corliss  fresh  114709   TIME Magazine   \n",
        "2           2         David Ansen  fresh  114709        Newsweek   \n",
        "3           3       Leonard Klady  fresh  114709         Variety   \n",
        "4           4  Jonathan Rosenbaum  fresh  114709  Chicago Reader   \n",
        "\n",
        "                                               quote review_date  rtid  \\\n",
        "0  So ingenious in concept, design and execution ...  2009-10-04  9559   \n",
        "1                  The year's most inventive comedy.  2008-08-31  9559   \n",
        "2  A winning animated feature that has something ...  2008-08-18  9559   \n",
        "3  The film sports a provocative and appealing st...  2008-06-09  9559   \n",
        "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559   \n",
        "\n",
        "       title  quote_len  quote_score  \n",
        "0  Toy story        137            3  \n",
        "1  Toy story         33            1  \n",
        "2  Toy story         79            4  \n",
        "3  Toy story        107            0  \n",
        "4  Toy story        110            2  "
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As the code below shows, there is not much of a correlation between the quote_score and freshness."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import statsmodels.formula.api as smf\n",
      "\n",
      "# create a fresh dummy variable\n",
      "c['f'] = c.fresh.map({'fresh': 1, 'rotten': 0})\n",
      "\n",
      "model = smf.ols(formula='f ~ quote_score', data=c)\n",
      "results = model.fit()\n",
      "print 'NORMAL FIT SUMMARY'\n",
      "print results.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NORMAL FIT SUMMARY\n",
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      f   R-squared:                       0.061\n",
        "Model:                            OLS   Adj. R-squared:                  0.061\n",
        "Method:                 Least Squares   F-statistic:                     908.0\n",
        "Date:                Mon, 09 Mar 2015   Prob (F-statistic):          2.43e-193\n",
        "Time:                        23:40:31   Log-Likelihood:                -9387.9\n",
        "No. Observations:               14049   AIC:                         1.878e+04\n",
        "Df Residuals:                   14047   BIC:                         1.879e+04\n",
        "Df Model:                           1                                         \n",
        "===============================================================================\n",
        "                  coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "-------------------------------------------------------------------------------\n",
        "Intercept       0.5653      0.004    131.892      0.000         0.557     0.574\n",
        "quote_score     0.0746      0.002     30.132      0.000         0.070     0.079\n",
        "==============================================================================\n",
        "Omnibus:                      383.901   Durbin-Watson:                   1.502\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1855.423\n",
        "Skew:                          -0.421   Prob(JB):                         0.00\n",
        "Kurtosis:                       1.432   Cond. No.                         1.98\n",
        "==============================================================================\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##6. Conclusions\n",
      "* The Bernoulli Naive Bayes algorithm seemed like a decent start, but it did basically the same as always picking \"fresh\" on the test data (with no less then 1.5M features at some point).\n",
      "* Other approaches are probably better, but there has to be a decent amount of munging to get there.\n",
      "* As my friend who works as a marketing consultant said \"why the F\\*\\*\\* are you doing sentiment analysis!? Even these guys from MIT with PhD's suck at it!\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}