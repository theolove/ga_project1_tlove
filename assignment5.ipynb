{
 "metadata": {
  "name": "",
  "signature": "sha256:4e0d6f3825a0c38e4a7c577d19bfb7ba5e32cf8647e1aafa0b82d3d01655917f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from __future__ import division\n",
      "import nltk\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from sklearn import naive_bayes, cross_validation, linear_model\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 5 - Fresh Predictions\n",
      "*Author - Theo Love*\n",
      "*Date - 3/9/2015*\n",
      "\n",
      "This is an extension of the work done on the Rotten Tomatoes database of critic reveiws to predict the \"freshness\" of a movie.\n",
      "\n",
      "**Contents**\n",
      "1. Helper Functions\n",
      "2. Data Import\n",
      "3. Exploration of N-Grams\n",
      "4. Smarter Parsing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##1. Helper Functions\n",
      "\n",
      "These functions are based on work done in class and will be used in the code below. In order to keep everything in one workbook, they have not been migrated to a separate module, but will probably be moved at some point in the future."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_measure(classifier, x, y, tsize=0.25, rstate=1234, print_details=False):\n",
      "    \"\"\"\n",
      "    Function accepts a classifer from sklearn and computes the accuracy measure for a random train and test split\n",
      "    and returns a tuple of (train accuracy, test accuracy)\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=tsize, random_state=rstate)\n",
      "    clf = classifier.fit(xtrain, ytrain)\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = clf.score(xtrain, ytrain)\n",
      "    test_accuracy = clf.score(xtest, ytest)\n",
      "    if print_details:\n",
      "        print classifier\n",
      "        print \"Accuracy on training data: %0.4f\" % (training_accuracy)\n",
      "        print \"Accuracy on test data:     %0.4f\" % (test_accuracy)\n",
      "    \n",
      "    return (training_accuracy, test_accuracy)\n",
      "\n",
      "def test_alphas_NB(x, y, tsize=0.25, rstate=1234, alphas=[1], multi=True):\n",
      "    \"\"\"\n",
      "    Return a dataframe of train/test scores for naive-bayes models at each alpha in a list.\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    alphas    : the list of alphas to test (optional, default is 1)\n",
      "    multi     : true for a Multinomial Naive-Bayes, false for Bernoulli (optional, default is True)\n",
      "    \"\"\"\n",
      "    trains = []\n",
      "    tests = []\n",
      "    for a in alphas:\n",
      "        if multi:\n",
      "            clf = naive_bayes.MultinomialNB(alpha=a)\n",
      "        else:\n",
      "            clf = naive_bayes.BernoulliNB(alpha=a)\n",
      "        r = train_and_measure(clf, x, y, tsize, rstate, print_details=False)\n",
      "        trains.append(r[0])\n",
      "        tests.append(r[1])\n",
      "\n",
      "    return pd.DataFrame({'alpha': alphas,\n",
      "                         'train_score': trains,\n",
      "                         'test_score': tests})\n",
      "\n",
      "def k_cross(classifier, x, y, nfolds=2, rstate=1234):\n",
      "    \"\"\"\n",
      "    Function that takes a classifier from sklearn and returns a tuple of the (mean, std dev) for a k-fold train/test\n",
      "    split on a dependent y vector and independent matrix x.\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of independent variables\n",
      "    y         : a vector for the dependent variable\n",
      "    nfolds    : the number of folds in the k-fold test (optional, default is 2)\n",
      "    rstate    : the seed for the random number generator in the k-fold shuffler (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    kfold = cross_validation.KFold(n=x.shape[0], n_folds=nfolds, shuffle=True, random_state=rstate)\n",
      "    train_acc = []\n",
      "    test_acc = []\n",
      "    \n",
      "    for train_index, test_index in kfold:\n",
      "        clf = classifier.fit(x[train_index], y[train_index])\n",
      "        train_acc.append(clf.score(x[train_index], y[train_index]))\n",
      "        test_acc.append(clf.score(x[test_index], y[test_index]))\n",
      "\n",
      "    return (np.array(test_acc).mean(), np.array(test_acc).std())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##2. Data Import"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in the data and get the length of the quotes\n",
      "critics = pd.read_csv('../DAT18NYC/data/rt_critics.csv')\n",
      "critics['quote_len'] = critics.quote.apply(lambda x: len(x))\n",
      "\n",
      "# print some pertinent data\n",
      "print \"Unique movies: %i\" % len(critics.title.unique())\n",
      "print \"Unique critics: %i\" % len(critics.critic.unique())\n",
      "print \"Fresh\\\\Rotten: %i\\\\%i\" % (len(critics[critics.fresh == 'fresh']), len(critics[critics.fresh == 'rotten']))\n",
      "print\n",
      "print \"Description of quote lengths\"\n",
      "print \"============================\"\n",
      "print critics.quote_len.describe()\n",
      "print \n",
      "print \"Columns\"\n",
      "print \"=======\"\n",
      "print critics.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique movies: 1736\n",
        "Unique critics: 622\n",
        "Fresh\\Rotten: 8613\\5436\n",
        "\n",
        "Description of quote lengths\n",
        "============================\n",
        "count    14072.000000\n",
        "mean       118.204946\n",
        "std         57.757129\n",
        "min          4.000000\n",
        "25%         73.000000\n",
        "50%        115.000000\n",
        "75%        160.000000\n",
        "max        256.000000\n",
        "dtype: float64\n",
        "\n",
        "Columns\n",
        "=======\n",
        "Index([u'critic', u'fresh', u'imdb', u'publication', u'quote', u'review_date', u'rtid', u'title', u'quote_len'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also interesting to see that a little less than 40% of the reviews are rotten, meaning that there is a bias towards \"fresh\" in the reviews.\n",
      "\n",
      "The summary of the data shows that the length of each quote is a maximum of 256 characters, which is rather small, and further suggests the usage of the Bernoulli implrementation of the Naive Bayes model. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##3. Exlporation of N-Grams\n",
      "\n",
      "The first new analysis to be done is to see if including additional number word groupings has any effect. Since the quotes are all rather short, the largest n-gram to be analyzed will be 5"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the y as the fresh column with a 1 or 0\n",
      "y = (critics.fresh == 'fresh').values.astype(int)\n",
      "\n",
      "# make a sparse matrix for a number of ngrams\n",
      "x1 = CountVectorizer(ngram_range=(1,1)).fit_transform(critics.quote)\n",
      "x2 = CountVectorizer(ngram_range=(2,2)).fit_transform(critics.quote)\n",
      "x3 = CountVectorizer(ngram_range=(3,3)).fit_transform(critics.quote)\n",
      "x4 = CountVectorizer(ngram_range=(4,4)).fit_transform(critics.quote)\n",
      "x5 = CountVectorizer(ngram_range=(5,5)).fit_transform(critics.quote)\n",
      "x1to2 = CountVectorizer(ngram_range=(1,2)).fit_transform(critics.quote)\n",
      "x1to3 = CountVectorizer(ngram_range=(1,3)).fit_transform(critics.quote)\n",
      "x1to4 = CountVectorizer(ngram_range=(1,4)).fit_transform(critics.quote)\n",
      "x1to5 = CountVectorizer(ngram_range=(1,5)).fit_transform(critics.quote)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show train/test scores for the BernoulliNB classifiers with varying alpha\n",
      "print \"N-grams = 1\"\n",
      "print test_alphas_NB((x1 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 2\"\n",
      "print test_alphas_NB((x2 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 3\"\n",
      "print test_alphas_NB((x3 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 4\"\n",
      "print test_alphas_NB((x4 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 5\"\n",
      "print test_alphas_NB((x5 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 2\"\n",
      "print test_alphas_NB((x1to2 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 3\"\n",
      "print test_alphas_NB((x1to3 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 4\"\n",
      "print test_alphas_NB((x1to4 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)\n",
      "print \"N-grams = 1 to 5\"\n",
      "print test_alphas_NB((x1to5 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "N-grams = 1\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612897     0.629516\n",
        "1  0.1000    0.610766     0.646690\n",
        "2  0.0100    0.610943     0.648466\n",
        "3  0.0010    0.610410     0.648111\n",
        "4  0.0001    0.609877     0.648229"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 2\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.607746     0.626555\n",
        "1  0.1000    0.607390     0.627384\n",
        "2  0.0100    0.608101     0.627739\n",
        "3  0.0010    0.607568     0.627739\n",
        "4  0.0001    0.607213     0.627857"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 3\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610410     0.617198\n",
        "1  0.1000    0.610410     0.617198\n",
        "2  0.0100    0.610410     0.617198\n",
        "3  0.0010    0.610766     0.617198\n",
        "4  0.0001    0.611476     0.617198"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 4\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.614592\n",
        "1  0.1000    0.610055     0.614592\n",
        "2  0.0100    0.610055     0.614592\n",
        "3  0.0010    0.610055     0.614592\n",
        "4  0.0001    0.610233     0.614592"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 5\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.613763\n",
        "1  0.1000    0.610055     0.613763\n",
        "2  0.0100    0.610055     0.613763\n",
        "3  0.0010    0.610055     0.613763\n",
        "4  0.0001    0.610055     0.613763"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 2\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612187     0.631529\n",
        "1  0.1000    0.609167     0.648822\n",
        "2  0.0100    0.610233     0.653914\n",
        "3  0.0010    0.609877     0.653796\n",
        "4  0.0001    0.608812     0.653441"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 3\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.611654     0.631292\n",
        "1  0.1000    0.608989     0.647400\n",
        "2  0.0100    0.610055     0.651783\n",
        "3  0.0010    0.609167     0.654151\n",
        "4  0.0001    0.609167     0.653441"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 4\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.611832     0.631292\n",
        "1  0.1000    0.609344     0.647045\n",
        "2  0.0100    0.610055     0.650953\n",
        "3  0.0010    0.610233     0.653559\n",
        "4  0.0001    0.609344     0.653559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "N-grams = 1 to 5\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.612009     0.631292\n",
        "1  0.1000    0.609700     0.646690\n",
        "2  0.0100    0.610233     0.650717\n",
        "3  0.0010    0.610943     0.653678\n",
        "4  0.0001    0.610055     0.653559"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These results show a few interesting things:\n",
      "\n",
      "1. Improvements in accuracy as alpha is decreased level out at around alpha = 0.01 (which will be used going forward)\n",
      "2. There is a slight decrease in the training score for single level n-grams, but not much of an affect on the test score. In general the testing score stays at 61%, and the range between the two gets tighter.\n",
      "3. There is not much improvement in accuracy for including higher ngrams, and in general the accuracy levels out at about 65% train / 61% test, which is still a nice tight range.\n",
      "\n",
      "Next we will examine confusion matrices"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# show confusion matrix for each of the ngram x sets\n",
      "print \"Bernoulli Confusion Matrix\"\n",
      "print \"[[False, FalsePos]\"\n",
      "print \" [FalseNeg, True]]\"\n",
      "print\n",
      "clf = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "\n",
      "print \"Constant Size NGrams\"\n",
      "print \"====================\"\n",
      "print \"NGrams = 1\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1))\n",
      "print \"NGrams = 2\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x2))\n",
      "print \"NGrams = 3\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x3, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x3))\n",
      "print \"NGrams = 4\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x4, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x4))\n",
      "print \"NGrams = 5\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x5, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x5))\n",
      "print\n",
      "\n",
      "print \"Increasing Size NGrams\"\n",
      "print \"======================\"\n",
      "print \"NGrams = 1 to 2\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to2))\n",
      "print \"NGrams = 1 to 3\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to3, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to3))\n",
      "print \"NGrams = 1 to 4\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to4, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to4))\n",
      "print \"NGrams = 1 to 5\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to5, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Bernoulli Confusion Matrix\n",
        "[[False, FalsePos]\n",
        " [FalseNeg, True]]\n",
        "\n",
        "Constant Size NGrams\n",
        "====================\n",
        "NGrams = 1\n",
        "[[3507 1952]\n",
        " [4458 4155]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 2\n",
        "[[4773  686]\n",
        " [7159 1454]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 3\n",
        "[[5250  209]\n",
        " [8220  393]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 4\n",
        "[[5150  309]\n",
        " [8134  479]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 5\n",
        "[[5012  447]\n",
        " [7932  681]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "Increasing Size NGrams\n",
        "======================\n",
        "NGrams = 1 to 2\n",
        "[[4503  956]\n",
        " [6284 2329]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 3\n",
        "[[5082  377]\n",
        " [7518 1095]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 4\n",
        "[[5252  207]\n",
        " [8019  594]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 1 to 5\n",
        "[[5319  140]\n",
        " [8203  410]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While the accuracy of the training went up slightly with more ngrams, the test accuracy remained similar. Drilling down with a confusion matrix we see a much clearer trend of a major issue with false negatives, and a drastic cut in the number of true guesses.\n",
      "\n",
      "Essentially, the main difference between the models is that they are all aorund 61% accurate, but including additional n-grams tilts results drastically negative and makes the number of false negatives through the roof.\n",
      "\n",
      "It is also worth pointing out, however that this is essentially as good a performance as always choosing \"fresh\"...\n",
      "\n",
      "Let's see if we can do some additional wrangling to help with our false-negative problem."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##4. Smarter Parsing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "clf = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "clf_new = naive_bayes.MultinomialNB(alpha=0.01)\n",
      "x_new = CountVectorizer(ngram_range=(1,2), stop_words='english').fit_transform(critics.quote)\n",
      "\n",
      "train_and_measure(clf, (x1to2 > 1), y, tsize=0.4, print_details=True)\n",
      "train_and_measure(clf, x_new, y, tsize=0.4, print_details=True)\n",
      "\n",
      "# show confusion matrix for each of the ngram x sets\n",
      "print \"Bernoulli Confusion Matrix\"\n",
      "print \"[[False, FalsePos]\"\n",
      "print \" [FalseNeg, True]]\"\n",
      "print\n",
      "\n",
      "print \"normal\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x1to2, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x1to2))\n",
      "print \"w/o stop words\"\n",
      "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x_new, y, test_size=.4, random_state=1234)\n",
      "clf.fit((xtrain > 1), ytrain)\n",
      "print confusion_matrix(y, clf.predict(x_new))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6525\n",
        "Accuracy on test data:     0.6090\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.9985\n",
        "Accuracy on test data:     0.6797\n",
        "Bernoulli Confusion Matrix\n",
        "[[False, FalsePos]\n",
        " [FalseNeg, True]]\n",
        "\n",
        "normal\n",
        "[[4503  956]\n",
        " [6284 2329]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "w/o stop words\n",
        "[[4694  765]\n",
        " [6801 1812]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t1 = clf.fit((x1>1), y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# modify the critics quote column\n",
      "def clean_quote(q):\n",
      "    import string\n",
      "    import re\n",
      "    return \"hello\"\n",
      "\n",
      "critics['q_new'] = critics.quote.apply(lambda x: clean_quote(x))\n",
      "\n",
      "clf = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "x = CountVectorizer(ngram_range=(1,2)).fit_transform(critics.q_new)\n",
      "train_and_measure(clf, (x > 1), y, tsize=0.4, print_details=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6142\n",
        "Accuracy on test data:     0.6088\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "(0.61423664574203485, 0.60881151181382132)"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Multinomial\"\n",
      "clf = naive_bayes.MultinomialNB(alpha=0.01)\n",
      "\n",
      "print \"NGrams = 1\"\n",
      "clf.fit(x1, y)\n",
      "print confusion_matrix(y, clf.predict(x1))\n",
      "\n",
      "print \"NGrams = 2\"\n",
      "clf.fit(x2, y)\n",
      "print confusion_matrix(y, clf.predict(x2))\n",
      "\n",
      "print \"NGrams = 3\"\n",
      "clf.fit(x3, y)\n",
      "print confusion_matrix(y, clf.predict(x3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Multinomial\n",
        "NGrams = 1\n",
        "[[5106  353]\n",
        " [ 416 8197]]\n",
        "NGrams = 2\n",
        "[[5453    6]\n",
        " [  10 8603]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NGrams = 3\n",
        "[[5455    4]\n",
        " [   6 8607]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# let us use the text2sentiment tool to get a sentiment score for each quote\n",
      "import json\n",
      "import requests\n",
      "\n",
      "def sentiment_score(sentence):\n",
      "    url = 'http://www.datasciencetoolkit.org/text2sentiment/'\n",
      "    payload = {'text': sentence} # The sentence we want the sentiment of \n",
      "    headers = {'content-type': 'application/json'} # The type of data you are sending\n",
      "    r = requests.post(url, data=json.dumps(payload), headers=headers) # Send the data\n",
      "    return sentence, json.loads(r.text)['score'] # Print the results\n",
      "\n",
      "critics['quote_score'] = critics.quote.apply(lambda x: sentiment_score(x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 79
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above took 20 minutes to run so we will just save the results to CSV now and come back to analyze later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics['qs'] = critics.quote_score.apply(lambda x: x[1])\n",
      "critics.to_csv('critics_tl.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tester = pd.read_csv('critics_tl.csv')\n",
      "tester.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>critic</th>\n",
        "      <th>fresh</th>\n",
        "      <th>imdb</th>\n",
        "      <th>publication</th>\n",
        "      <th>quote</th>\n",
        "      <th>review_date</th>\n",
        "      <th>rtid</th>\n",
        "      <th>title</th>\n",
        "      <th>quote_len</th>\n",
        "      <th>q_new</th>\n",
        "      <th>quote_score</th>\n",
        "      <th>qs</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td>        Derek Adams</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Time Out</td>\n",
        "      <td> So ingenious in concept, design and execution ...</td>\n",
        "      <td> 2009-10-04</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 137</td>\n",
        "      <td> hello</td>\n",
        "      <td> ('So ingenious in concept, design and executio...</td>\n",
        "      <td> 3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td>    Richard Corliss</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>  TIME Magazine</td>\n",
        "      <td>                 The year's most inventive comedy.</td>\n",
        "      <td> 2008-08-31</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  33</td>\n",
        "      <td> hello</td>\n",
        "      <td>        (\"The year's most inventive comedy.\", 1.0)</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td>        David Ansen</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>       Newsweek</td>\n",
        "      <td> A winning animated feature that has something ...</td>\n",
        "      <td> 2008-08-18</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td>  79</td>\n",
        "      <td> hello</td>\n",
        "      <td> ('A winning animated feature that has somethin...</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td>      Leonard Klady</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td>        Variety</td>\n",
        "      <td> The film sports a provocative and appealing st...</td>\n",
        "      <td> 2008-06-09</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 107</td>\n",
        "      <td> hello</td>\n",
        "      <td> (\"The film sports a provocative and appealing ...</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> Jonathan Rosenbaum</td>\n",
        "      <td> fresh</td>\n",
        "      <td> 114709</td>\n",
        "      <td> Chicago Reader</td>\n",
        "      <td> An entertaining computer-generated, hyperreali...</td>\n",
        "      <td> 2008-03-10</td>\n",
        "      <td> 9559</td>\n",
        "      <td> Toy story</td>\n",
        "      <td> 110</td>\n",
        "      <td> hello</td>\n",
        "      <td> (\"An entertaining computer-generated, hyperrea...</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "   Unnamed: 0              critic  fresh    imdb     publication  \\\n",
        "0           0         Derek Adams  fresh  114709        Time Out   \n",
        "1           1     Richard Corliss  fresh  114709   TIME Magazine   \n",
        "2           2         David Ansen  fresh  114709        Newsweek   \n",
        "3           3       Leonard Klady  fresh  114709         Variety   \n",
        "4           4  Jonathan Rosenbaum  fresh  114709  Chicago Reader   \n",
        "\n",
        "                                               quote review_date  rtid  \\\n",
        "0  So ingenious in concept, design and execution ...  2009-10-04  9559   \n",
        "1                  The year's most inventive comedy.  2008-08-31  9559   \n",
        "2  A winning animated feature that has something ...  2008-08-18  9559   \n",
        "3  The film sports a provocative and appealing st...  2008-06-09  9559   \n",
        "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559   \n",
        "\n",
        "       title  quote_len  q_new  \\\n",
        "0  Toy story        137  hello   \n",
        "1  Toy story         33  hello   \n",
        "2  Toy story         79  hello   \n",
        "3  Toy story        107  hello   \n",
        "4  Toy story        110  hello   \n",
        "\n",
        "                                         quote_score  qs  \n",
        "0  ('So ingenious in concept, design and executio...   3  \n",
        "1         (\"The year's most inventive comedy.\", 1.0)   1  \n",
        "2  ('A winning animated feature that has somethin...   4  \n",
        "3  (\"The film sports a provocative and appealing ...   0  \n",
        "4  (\"An entertaining computer-generated, hyperrea...   2  "
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "84/60"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "1.4"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m1 = naive_bayes.BernoulliNB(alpha=0.01).fit((x1to5>1), y)\n",
      "len(m1.feature_count_[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 78,
       "text": [
        "813369"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lm1.fit(np.array(critics.qs), y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "tuple index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-89-b910df274240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, n_jobs)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         X, y, X_mean, y_mean, X_std = self._center_data(\n\u001b[0;32m--> 355\u001b[0;31m             X, y, self.fit_intercept, self.normalize, self.copy_X)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mcenter_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mX_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mX_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0my_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics['qs'] = critics.quote_score.apply(lambda x: x[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "critics.qs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "0     3.000000\n",
        "1     1.000000\n",
        "2     4.000000\n",
        "3     0.000000\n",
        "4     2.000000\n",
        "5     1.500000\n",
        "6     2.500000\n",
        "7     2.750000\n",
        "8     2.000000\n",
        "9     3.333333\n",
        "10    3.000000\n",
        "11    3.000000\n",
        "12    0.000000\n",
        "13    2.000000\n",
        "14   -0.500000\n",
        "...\n",
        "14057    0.0\n",
        "14058    0.0\n",
        "14059    0.0\n",
        "14060    1.0\n",
        "14061    1.0\n",
        "14062    0.0\n",
        "14063    1.0\n",
        "14064    0.0\n",
        "14065    2.5\n",
        "14066    0.0\n",
        "14067    1.0\n",
        "14068   -2.0\n",
        "14069    0.8\n",
        "14070    2.0\n",
        "14071    1.0\n",
        "Name: qs, Length: 14072, dtype: float64"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}