{
 "metadata": {
  "name": "",
  "signature": "sha256:fb01ea56ae9c96dc7f77d6f9682f6d015ae5ad113311ebf65a8b08c213ff4468"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "from __future__ import division\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "from sklearn import naive_bayes, cross_validation, linear_model\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.metrics import confusion_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# read in the data and get the length of the quotes\n",
      "critics = pd.read_csv('../DAT18NYC/data/rt_critics.csv')\n",
      "critics['quote_len'] = critics.quote.apply(lambda x: len(x))\n",
      "\n",
      "# print some pertinent data\n",
      "print \"Unique movies: %i\" % len(critics.title.unique())\n",
      "print \"Unique critics: %i\" % len(critics.critic.unique())\n",
      "print \"Fresh\\\\Rotten: %i\\\\%i\" % (len(critics[critics.fresh == 'fresh']), len(critics[critics.fresh == 'rotten']))\n",
      "print\n",
      "print \"Description of quote lengths\"\n",
      "print \"============================\"\n",
      "print critics.quote_len.describe()\n",
      "print \n",
      "print \"Columns\"\n",
      "print \"=======\"\n",
      "print critics.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Unique movies: 1736\n",
        "Unique critics: 622\n",
        "Fresh\\Rotten: 8613\\5436\n",
        "\n",
        "Description of quote lengths\n",
        "============================\n",
        "count    14072.000000\n",
        "mean       118.204946\n",
        "std         57.757129\n",
        "min          4.000000\n",
        "25%         73.000000\n",
        "50%        115.000000\n",
        "75%        160.000000\n",
        "max        256.000000\n",
        "Name: quote_len, dtype: float64\n",
        "\n",
        "Columns\n",
        "=======\n",
        "Index([u'critic', u'fresh', u'imdb', u'publication', u'quote', u'review_date', u'rtid', u'title', u'quote_len'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define the y as the fresh column with a 1 or 0\n",
      "y = (critics.fresh == 'fresh').values.astype(int)\n",
      "\n",
      "# make a vectorizers for ngrams of 1, 1 to 2, and 1 to 3\n",
      "vzr_1 = CountVectorizer(ngram_range=(1,1))\n",
      "vzr_2 = CountVectorizer(ngram_range=(1,2))\n",
      "vzr_3 = CountVectorizer(ngram_range=(1,3))\n",
      "x1 = vzr_1.fit_transform(critics.quote)\n",
      "x2 = vzr_2.fit_transform(critics.quote)\n",
      "x3 = vzr_3.fit_transform(critics.quote)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def train_and_measure(classifier, x, y, tsize=0.25, rstate=1234):\n",
      "    \"\"\"\n",
      "    Function accepts a classifer from sklearn and computes the accuracy measure for a random train and test split\n",
      "    and returns a tuple of (train accuracy, test accuracy)\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=tsize, random_state=rstate)\n",
      "    clf = classifier.fit(xtrain, ytrain)\n",
      "\n",
      "    #Print the accuracy on the test and training dataset\n",
      "    training_accuracy = clf.score(xtrain, ytrain)\n",
      "    test_accuracy = clf.score(xtest, ytest)\n",
      "    print classifier\n",
      "    print \"Accuracy on training data: %0.4f\" % (training_accuracy)\n",
      "    print \"Accuracy on test data:     %0.4f\" % (test_accuracy)\n",
      "    return (training_accuracy, test_accuracy)\n",
      "\n",
      "def test_alphas_NB(x, y, tsize=0.25, rstate=1234, alphas=[1], multi=True):\n",
      "    \"\"\"\n",
      "    Return a dataframe of train/test scores for naive-bayes models at each alpha in a list.\n",
      "    x         : a matrix of features\n",
      "    y         : a vector of targets\n",
      "    tsize     : the test size as a percent of the data (optional, default is 25%)\n",
      "    rstate    : the random number seed (optional, default is 1234)\n",
      "    alphas    : the list of alphas to test (optional, default is 1)\n",
      "    multi     : true for a Multinomial Naive-Bayes, false for Bernoulli (optional, default is True)\n",
      "    \"\"\"\n",
      "    trains = []\n",
      "    tests = []\n",
      "    for a in alphas:\n",
      "        print \"ALPHA = %f\" % a\n",
      "        if multi:\n",
      "            clf = naive_bayes.MultinomialNB(alpha=a)\n",
      "        else:\n",
      "            clf = naive_bayes.BernoulliNB(alpha=a)\n",
      "        r = train_and_measure(clf, x, y, tsize, rstate)\n",
      "        trains.append(r[0])\n",
      "        tests.append(r[1])\n",
      "        print\n",
      "\n",
      "    return pd.DataFrame({'alpha': alphas,\n",
      "                         'train_score': trains,\n",
      "                         'test_score': tests})\n",
      "\n",
      "def k_cross(classifier, x, y, nfolds=2, rstate=1234):\n",
      "    \"\"\"\n",
      "    Function that takes a classifier from sklearn and returns a tuple of the (mean, std dev) for a k-fold train/test\n",
      "    split on a dependent y vector and independent matrix x.\n",
      "    classifier: an sklearn class\n",
      "    x         : a matrix of independent variables\n",
      "    y         : a vector for the dependent variable\n",
      "    nfolds    : the number of folds in the k-fold test (optional, default is 2)\n",
      "    rstate    : the seed for the random number generator in the k-fold shuffler (optional, default is 1234)\n",
      "    \"\"\"\n",
      "    kfold = cross_validation.KFold(n=x.shape[0], n_folds=nfolds, shuffle=True, random_state=rstate)\n",
      "    train_acc = []\n",
      "    test_acc = []\n",
      "    \n",
      "    for train_index, test_index in kfold:\n",
      "        clf = classifier.fit(x[train_index], y[train_index])\n",
      "        train_acc.append(clf.score(x[train_index], y[train_index]))\n",
      "        test_acc.append(clf.score(x[test_index], y[test_index]))\n",
      "\n",
      "    return (np.array(test_acc).mean(), np.array(test_acc).std())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s1 = test_alphas_NB((x1 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], False)\n",
      "s2 = test_alphas_NB((x2 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], False)\n",
      "s3 = test_alphas_NB((x3 > 1), y, 0.4, 2345, [10**-i for i in range(0,5)], False)\n",
      "\n",
      "print s1\n",
      "print s2\n",
      "print s3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ALPHA = 1.000000\n",
        "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6151\n",
        "Accuracy on test data:     0.6104\n",
        "\n",
        "ALPHA = 0.100000\n",
        "BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6467\n",
        "Accuracy on test data:     0.6108\n",
        "\n",
        "ALPHA = 0.010000\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6483\n",
        "Accuracy on test data:     0.6111\n",
        "\n",
        "ALPHA = 0.001000\n",
        "BernoulliNB(alpha=0.001, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6494\n",
        "Accuracy on test data:     0.6104\n",
        "\n",
        "ALPHA = 0.000100\n",
        "BernoulliNB(alpha=0.0001, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6495\n",
        "Accuracy on test data:     0.6104\n",
        "\n",
        "ALPHA = 1.000000\n",
        "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6134\n",
        "Accuracy on test data:     0.6101\n",
        "\n",
        "ALPHA = 0.100000\n",
        "BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6433\n",
        "Accuracy on test data:     0.6090\n",
        "\n",
        "ALPHA = 0.010000\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6538\n",
        "Accuracy on test data:     0.6093\n",
        "\n",
        "ALPHA = 0.001000\n",
        "BernoulliNB(alpha=0.001, binarize=0.0, class_prior=None, fit_prior=True)\n",
        "Accuracy on training data: 0.6547\n",
        "Accuracy on test data:     0.6083\n",
        "\n",
        "ALPHA = 0.000100\n",
        "BernoulliNB(alpha=0.0001, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6540\n",
        "Accuracy on test data:     0.6093\n",
        "\n",
        "ALPHA = 1.000000\n",
        "BernoulliNB(alpha=1, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6134\n",
        "Accuracy on test data:     0.6101\n",
        "\n",
        "ALPHA = 0.100000\n",
        "BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6241\n",
        "Accuracy on test data:     0.6093\n",
        "\n",
        "ALPHA = 0.010000\n",
        "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6523\n",
        "Accuracy on test data:     0.6108\n",
        "\n",
        "ALPHA = 0.001000\n",
        "BernoulliNB(alpha=0.001, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6549\n",
        "Accuracy on test data:     0.6097\n",
        "\n",
        "ALPHA = 0.000100\n",
        "BernoulliNB(alpha=0.0001, binarize=0.0, class_prior=None, fit_prior=True)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.6540\n",
        "Accuracy on test data:     0.6101\n",
        "\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610410     0.615066\n",
        "1  0.1000    0.610766     0.646690\n",
        "2  0.0100    0.611121     0.648348\n",
        "3  0.0010    0.610410     0.649414\n",
        "4  0.0001    0.610410     0.649532\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.613408\n",
        "1  0.1000    0.608989     0.643255\n",
        "2  0.0100    0.609344     0.653796\n",
        "3  0.0010    0.608279     0.654744\n",
        "4  0.0001    0.609344     0.654033\n",
        "    alpha  test_score  train_score\n",
        "0  1.0000    0.610055     0.613408\n",
        "1  0.1000    0.609344     0.624067\n",
        "2  0.0100    0.610766     0.652256\n",
        "3  0.0010    0.609700     0.654862\n",
        "4  0.0001    0.610055     0.654033\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_measure(linear_model.LogisticRegression(), x1, y, 0.6, 2345)\n",
      "train_and_measure(linear_model.LogisticRegression(), x2, y, 0.6, 2345)\n",
      "train_and_measure(linear_model.LogisticRegression(), x3, y, 0.6, 2345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "Accuracy on training data: 0.9726\n",
        "Accuracy on test data:     0.7605\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.9996\n",
        "Accuracy on test data:     0.7641\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.9998\n",
        "Accuracy on test data:     0.7545\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(0.99976311737534052, 0.75448569905844731)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_and_measure(linear_model.LogisticRegression(), x1, y, 0.6, 2345)\n",
      "train_and_measure(linear_model.LogisticRegression(), x2, y, 0.6, 2345)\n",
      "train_and_measure(linear_model.LogisticRegression(), x3, y, 0.6, 2345)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)\n",
        "Accuracy on training data: 0.9822\n",
        "Accuracy on test data:     0.7469\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.9995\n",
        "Accuracy on test data:     0.7457\n",
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Accuracy on training data: 0.9996\n",
        "Accuracy on test data:     0.7370\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "(0.99964463397299219, 0.73697299857887255)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cls = naive_bayes.BernoulliNB(alpha=0.01)\n",
      "\n",
      "k1 = k_cross(cls, (x1 > 1), y, 4)\n",
      "k2 = k_cross(cls, (x2 > 1), y, 4)\n",
      "k3 = k_cross(cls, (x3 > 1), y, 4)\n",
      "\n",
      "print k1\n",
      "print k2\n",
      "print k3\n",
      "\n",
      "plt.figure(figsize=(10,5))\n",
      "plt.subplot(111) \n",
      "sns.kdeplot(np.random.normal(loc=k1[0], scale=k1[1], size=10000), shade=True)\n",
      "plt.subplot(121)\n",
      "sns.kdeplot(np.random.normal(loc=k1[0], scale=k1[1], size=10000), shade=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.61178226264923241, 0.0051495014253815814)\n",
        "(0.61192438885730538, 0.0062515339910423767)\n",
        "(0.61149801023308692, 0.007270349447831107)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "<matplotlib.axes._subplots.AxesSubplot at 0x10c131e90>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAE7CAYAAAALqO5TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8Aghqk6CRwhRdRI8Qoiq+/8L99nAiunjwwAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10fc3de50>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print k1\n",
      "print k2\n",
      "print k3"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(0.60950824332006825, 0.0037663445139283769)\n",
        "(0.60837123365548607, 0.0036242183058555755)\n",
        "(0.61156907333712329, 0.0025582717453098147)\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}